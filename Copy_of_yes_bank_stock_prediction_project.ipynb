{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "PoPl-ycgm1ru",
        "F6T5p64dYrdO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n",
        "# **YES Bank Stock Closing Price Prediction**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "  # Ritika Sharma  "
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Financial forecasting plays a crucial role in stock market analysis, investment planning, and risk assessment. This project focuses on predicting closing prices using historical data and machine learning techniques. The dataset includes key financial indicators such as Open, High, Low, Close prices and Date. The primary objective is to develop an accurate regression model that generalizes well to unseen data while minimizing prediction errors.\n",
        "\n",
        "Data Cleaning & Preprocessing\n",
        "\n",
        "Before training the models, extensive data cleaning was performed to enhance model performance. This included:\n",
        "\n",
        "Removing outliers using Interquartile Range (IQR) to prevent extreme values from skewing predictions.\n",
        "\n",
        "Handling skewness using log transformation, ensuring normally distributed features.\n",
        "\n",
        "Feature scaling using StandardScaler to maintain consistency across different models.\n",
        "\n",
        "The cleaned dataset was then split into training (80%) and testing (20%) sets for model evaluation.\n",
        "\n",
        "Models Implemented & Performance Analysis\n",
        "\n",
        "Tested multiple regression models to identify the best-performing algorithm:\n",
        "\n",
        "Linear Regression.\n",
        "\n",
        "Decision Tree Regressor.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since 2018, It has been in the news because of the fraud case invloving Rana Kapoor. Owing to this fact, it was intresting to see how that impacted the stock prices of the company and whether time series model or any other predictive model can do justice to such situations. Stock price prediction is a complex and highly dynamic task due to various market factors. One such major factor is 2018 fraud case, which might have significantly fluctuated stock prices. The goal is to analyze historical stock price data and develop a model that can provide reliable future price estimates."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Objective**"
      ],
      "metadata": {
        "id": "PH-0ReGfmX4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main objective is to predict the stocks's closing price of the month"
      ],
      "metadata": {
        "id": "PhDvGCAqmjP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mplfinance"
      ],
      "metadata": {
        "id": "ukvn-mUo5kkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy.stats import norm\n",
        "import mplfinance as mpf"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# store the data in variable \"df\".\n",
        "df = pd.read_csv(\"/content/sample_data/data_YesBank_StockPrices.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Displays all rows\n",
        "pd.set_option('display.max_rows', None) # if want to show specific number of rows, provide the number instead of 'None'"
      ],
      "metadata": {
        "id": "itCrlXvlKBaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First appearnace of the data\n",
        "df"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Hnl17b3N4uQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# provide the column name,nonnull count and datatype of the column with the important info function\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y', errors='coerce')# Convert 'Date' column to datetime, assuming years are in the 2000s\n",
        "df.info()"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set date column as the index of the dataset\n",
        "df.set_index(\"Date\",inplace = True)"
      ],
      "metadata": {
        "id": "NmuzI5Rq8gXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# give all the columns name present in the data\n",
        "df.columns"
      ],
      "metadata": {
        "id": "jrCfSvOIK4V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mini statistics of the data give by function dot describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding duplicate and then drop it permanently\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "H37QBA3pPRGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle Missing Data (if any)\n",
        "\n",
        "If any missing values are found in Open, High, Low, or Close, fill them using:\n",
        "\n",
        "Forward-fill (ffill())\n",
        "\n",
        "Backward-fill (bfill())\n",
        "\n",
        "Interpolation (interpolate())"
      ],
      "metadata": {
        "id": "06MU2kmSt422"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "# there is no missing values in the dataset"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is a time series dataset. A time series dataset is a collection of data points ordered in time, where each data entry corresponds to a specific timestamp. Time series data is used to analyze trends, patterns, and future predictions.\n",
        "\n",
        "Key Characteristics of Time Series Data\n",
        "\n",
        "Time Dependency → The order of data matters, as past values influence future ones.\n",
        "\n",
        "Regular Intervals → Data is often recorded at consistent intervals (daily, hourly, monthly, etc.).\n",
        "\n",
        "Trend & Seasonality → Time series data often exhibits trends (long-term growth/decline) and seasonal patterns (recurring fluctuations).\n",
        "\n",
        "Autocorrelation → Future values can be correlated with past values.\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding The Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Variables Description\" refers to explaining each column (feature) in the dataset.It helps better understand the data\n",
        "\n",
        "Date  -The date of the record\tDateTime\t-\n",
        "\n",
        "Open  -Opening price of the stock on that month\n",
        "\n",
        "High  -Highest price of the stock on that month\n",
        "\n",
        "Low   -Lowest price of the stock on that month\n",
        "\n",
        "Close -Closing price of the stock on that month"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns :\n",
        "  print(col,df[col].nunique())\n",
        "  print()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Feature engineering:\n",
        "\n",
        "create  new features like month and year\n",
        "\n",
        "##### 2. compute  moving averages:\n",
        "\n",
        "##### 3. compute volatility:\n",
        "\n",
        "##### 4. compute percentage change:\n"
      ],
      "metadata": {
        "id": "fQ_siK1svuaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code to make your dataset analysis ready.\n",
        "df[\"Month\"] = df.index.month\n",
        "df[\"Year\"] = df.index.year"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting five sample data point to see the code result in our data.\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "Y2chgv-8w4yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing moving average over two month\n",
        "# it smooths out price fluctuations and helps identify trends\n",
        "# if price is above the moving avg ,its an uptrend otherwise is a low trend\n",
        "df[\"Moving_Average\"] = df[\"Close\"].rolling(window=5).mean()"
      ],
      "metadata": {
        "id": "4c3ou3D1xxBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(df[\"Close\"].mean(),2)"
      ],
      "metadata": {
        "id": "T5xkMF5CzEyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fill NaN values using backward fill\n",
        "df = df.fillna(method='bfill')\n",
        "df"
      ],
      "metadata": {
        "id": "WyqqOjJ_6l2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Volatility: Measures how much the price fluctuates over time.\n",
        "\n",
        "* High volatility means rapid price movements (riskier but good for traders).\n",
        "\n",
        "* Low volatility means stable prices (safer for long-term investors).\n",
        "\n"
      ],
      "metadata": {
        "id": "Iw7MEZeB7rLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check volatility of the stock\n",
        "df['Volatility'] = df['High'] - df['Low']\n",
        "df.sample(10)"
      ],
      "metadata": {
        "id": "Csq-lgWe6-hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Percentage change: Measures the percentage increase or decrease in price from the previous period.\n",
        "\n",
        "* A positive percentage change → Price is increasing.\n",
        "\n",
        "* A negative percentage change → Price is decreasing.\n",
        "\n",
        "* Consistently high % change → Strong trend or breakout.\n"
      ],
      "metadata": {
        "id": "2vKczJXb-5XG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute percentage change in the stock over the periods.\n",
        "df['Return'] = df['Close'].pct_change()"
      ],
      "metadata": {
        "id": "LBIVvQmJ7C4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna(method='bfill')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CHQRjFgTAB8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trend we observe in the Moving Average (MA) column suggests an overall rise, peak, and decline in the stock's price over the selected period.\n",
        "\n",
        "1.During the opening time of the bank there was increase in the stock's prices indicating bullish trend that there are more buyers and high popularity of the stock.\n",
        "\n",
        "2.In the middle , the stock get to its highest prices shows market peak .\n",
        "\n",
        "3.During the end periods or say the fraud time the stocks prices again starts decreasing simply idicating a bearish trend."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "sns.lineplot(x=df.index,y=df['Close'])\n",
        "plt.title('Closing Price Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially , there is a increasing trend in the stock closing price. then there is a saturation around 17-19 and then there is sudden decrease in the year 2019 and then there is continuous descrese in the price."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The positive impact is that, We can find the reason for the downfall and simply work on that to get back to bullish trend."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "sns.barplot(x=df['Year'],y=df['Moving_Average'])#ci= none will remove the confidence interval from the bars\n",
        "plt.title('Moving Average Over Time')\n",
        "plt.xlabel('Year')\n",
        "plt.xticks(rotation = 45)\n",
        "plt.ylabel('Moving Average')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the insights over every year i need to create bin of every year hence use the bar plot for the same.there is high fluctuation during 2016 ,17,18 and 19."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The black line you see over each bar in your bar chart represents the error bars or confidence intervals.\n",
        "\n",
        "Longer black lines → More variability (higher standard deviation) in the moving average values for that year.\n",
        "\n",
        "Shorter black lines → Less variability (more stable values).\n",
        "\n",
        "No black lines → Indicates no variation (or error bars are disabled).\n",
        "\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the year of 2016 , public loose confidence in the stock of the bank and till end it reamain the same and get highest in the year 2019."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "sns.barplot(x=df['Year'],y=df['Volatility'])\n",
        "plt.title('Volatility Over Time')\n",
        "plt.xlabel('Year')\n",
        "plt.xticks(rotation= 45)\n",
        "plt.ylabel('Volatility')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Over time , I want to compare the volatility in the closing price of the stock"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the year 2018 has the highest volatility in the stock price."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is something wrong in the year 2018 with the business which is need to be figured out and then be resolved to get the business back to normal trend."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "import mplfinance as mpf\n",
        "\n",
        "mpf.plot(df, type='candle', volume=False, style='charles', title='Stock Price Candlestick Chart')\n",
        "\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualizes market trends or  bullish/bearish pattern in the stock performance over the years."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest bearish behaviour is shown in year 2018 around in July."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excatly in 2018, we can find what exactly has happened in this time with the company."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "monthly_avg = df.groupby(\"Month\")[\"Close\"].mean()\n",
        "sns.barplot(x=monthly_avg.index, y=monthly_avg.values, palette=\"coolwarm\")\n",
        "plt.xlabel(\"Month\")\n",
        "plt.ylabel(\"Avg Closing Price\")\n",
        "plt.title(\"Average Monthly Closing Price\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " TO Compare stock performance across different months."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average closing pyaar is highest in the first quater of the year."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here , we can decide and take some actions for the other three quater to make the consistency in the stock price."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.scatter(df['Volatility'], df['Return'], color='purple', alpha=0.6)\n",
        "plt.xlabel(\"Volatility\")\n",
        "plt.ylabel(\"Return\")\n",
        "plt.title(\"Stock Return vs. Volatility\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shows risk-return tradeoff; higher volatility often means higher returns"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the correlation in the two column is negative. showing that if volatility is less then the returns are also low and as volatility increases the return start decreases."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could work on the stagnancy in the volatitlity of the stock price."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.hist(df['Return'], bins=30, color='blue', alpha=0.7)\n",
        "plt.xlabel(\"Return\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Stock Returns\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show how stock returns are distributed, identifying skewness & risk."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stock returns are normally distributed."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(df.index, df['Close'], label='Closing Price', color='blue')\n",
        "plt.plot(df.index,df['Moving_Average'], label='Moving Average', color='orange')\n",
        "plt.plot(df.index, df['Volatility'], label='Volatility', color='red', linestyle='dashed')\n",
        "plt.legend()\n",
        "plt.title('Stock Price, Moving Average & Volatility Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Values')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find relationships between different stock indicators."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "sns.boxplot(x=df[\"Month\"], y=df[\"Volatility\"], palette=\"pastel\")\n",
        "plt.xlabel(\"Month\")\n",
        "plt.ylabel(\"Volatility\")\n",
        "plt.title(\"Monthly Volatility Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " To shows how volatility varies by month and detects outliers"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "there is the highest volatility in the nineth month of the year.\n"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "fig, ax1 = plt.subplots(figsize=(10,5))\n",
        "\n",
        "ax1.set_xlabel(\"Date\")\n",
        "ax1.set_ylabel(\"Moving Average\", color='g')\n",
        "ax1.plot(df.index, df['Moving_Average'], color='g', label=\"Moving Average\")\n",
        "ax1.tick_params(axis='y', labelcolor='g')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel(\"Volatility\", color='r')\n",
        "ax2.plot(df.index, df['Volatility'], color='r', linestyle=\"dashed\", label=\"Volatility\")\n",
        "ax2.tick_params(axis='y', labelcolor='r')\n",
        "\n",
        "fig.suptitle(\"Moving Average & Volatility Trend\")\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare trends of volatility and stock trend movements."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in the end year of the data there is more volatility than the stock price trend indicating the wekaness in the stock."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.boxplot(y=df['Volatility'])\n",
        "plt.title('Box Plot of Stock Volatility')\n",
        "plt.ylabel('Volatility')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " To detect outliers in volatility, returns, or prices"
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(df.index, df['Moving_Average'], label='Moving Average', color='orange')\n",
        "plt.plot(df.index, df['Close'], label='Closing Price', color='blue', alpha=0.6)\n",
        "plt.legend()\n",
        "plt.title('Stock Prices & Moving Average Trend')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To observe the trend of stock prices & moving averages"
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bullish/bearish phases & price momentum."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "yearly_avg = df.groupby('Year')['Close'].mean()\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=yearly_avg.index, y=yearly_avg.values)\n",
        "plt.title('Average Closing Price per Year')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average Closing Price')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " To compare average stock prices for different year"
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highlights overall price movement over years.\n",
        "Data is left skewed"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.heatmap(df[['Close', 'Volatility', 'Return', 'Moving_Average']].corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Stock Data Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find relationships between different stock indicators."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifies how volatility, returns, and prices are related"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df[['Close', 'Volatility', 'Return', 'Moving_Average']])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visually explore correlations between key stock metrics."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Helps identify relationships between returns, prices, and volatility"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Histograms with KDE to detect skewness.***"
      ],
      "metadata": {
        "id": "iHGA5imWSKH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the columns to analyze\n",
        "columns = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Create subplots (2 rows, 2 columns)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "# Flatten the axes array for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through each column and plot\n",
        "for i, col in enumerate(columns):\n",
        "    sns.histplot(df[col], bins=30, kde=True, ax=axes[i], color='green', edgecolor='black')\n",
        "\n",
        "    # Calculate mean and median\n",
        "    mean_val = df[col].mean()\n",
        "    median_val = df[col].median()\n",
        "\n",
        "    # Plot mean and median as dashed lines\n",
        "    axes[i].axvline(mean_val, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
        "    axes[i].axvline(median_val, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median_val:.2f}')\n",
        "\n",
        "    # Add title and legend\n",
        "    axes[i].set_title(f'Distribution of {col}')\n",
        "    axes[i].legend()\n",
        "\n",
        "    # calculate Skewness for each column\n",
        "    skewness = df[col].skew()\n",
        "    axes[i].text(0.05, 0.95, f'Skewness: {skewness:.2f}', transform=axes[i].transAxes, fontsize=10, verticalalignment='top',horizontalalignment=\"right\")\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3E5wkTh0jNSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypothesis and Interpretation of above Histograms\n",
        "Hypothesis:\n",
        "\n",
        "The stock price variables (Open, High, Low, Close) might be right-skewed, indicating that most stock prices are concentrated in the lower range, with a few extreme values on the higher end.\n",
        "\n",
        "There could be a significant difference between the mean and median, which suggests potential skewness or outliers in the data.\n",
        "\n",
        "If skewness is high, the dataset might require transformations (e.g., log transformation) for better statistical modeling.\n",
        "\n",
        "Interpretation:\n",
        "The skewness values for Open (1.27), High (1.23), Low (1.30), and Close (1.26) indicate high positive skewness.\n",
        "\n",
        "If skewness is between -0.5 to 0.5 → Distribution is nearly symmetric (not a concern).\n",
        "\n",
        "If skewness is between 0.5 to 1.0 → Mild skewness (needs some attention).\n",
        "\n",
        "If skewness is above 1.0 → Highly skewed → This needs careful analysis!\n",
        "\n",
        "This confirms that the stock prices have a longer right tail, meaning that while most prices are low, some extreme values are present at the higher end. Mean vs. Median (Central Tendency):\n",
        "\n",
        "The red dashed line (Mean) is positioned to the right of the green dashed line (Median) in all distributions.\n",
        "\n",
        "This further confirms positive skewness, as the mean is being pulled toward the higher values due to a few high-priced stocks.\n",
        "\n",
        "The density curves (KDE) show a peak at lower values, reinforcing that most stock prices fall within a lower range.\n",
        "\n",
        "There are fewer instances of higher stock prices, contributing to the skewness. Potential Impact on Modeling:\n",
        "\n",
        "Since the data is skewed, some machine learning models (like linear regression) may not perform well due to non-normality.\n",
        "\n",
        "Conclusion:\n",
        "The stock price variables exhibit moderate positive skewness, meaning stock prices are not normally distributed.\n",
        "The difference between mean and median suggests the presence of outliers or extreme values.\n",
        "Transformations might be necessary before using statistical models that assume normality.\n",
        "Possible Solution:\n",
        "\n",
        "Applying log transformation to normalize the distributions."
      ],
      "metadata": {
        "id": "XYQJM6d2hNYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transform Data (Reduce Skewness and Outliers)"
      ],
      "metadata": {
        "id": "ZyAflmp1nUSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Compresses large values (reduces impact of high outliers).\n",
        "\n",
        "* Makes right-skewed distributions more normal.\n",
        "\n",
        "* Retains trends without losing extreme values."
      ],
      "metadata": {
        "id": "v48sGbognfJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Detecting Outliers**"
      ],
      "metadata": {
        "id": "-Vx6QKUSlxYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the columns where we want to detect outliers\n",
        "columns_to_check = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Creating a function to detect outliers\n",
        "def detect_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "\n",
        "    return outliers, lower_bound, upper_bound\n",
        "\n",
        "# Checking outliers for all columns\n",
        "for col in columns_to_check:\n",
        "    outliers, lb, ub = detect_outliers_iqr(df, col)\n",
        "    print(f\"Outliers in {col}: {len(outliers)}\")\n",
        "    print(f\"Lower Bound: {lb}, Upper Bound: {ub}\\n\")\n",
        "\n",
        "# using winsorization over droping the outliers so that do not miss any imp info.\n",
        "for col in columns_to_check:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
        "    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
        "\n"
      ],
      "metadata": {
        "id": "3YxnuxEHlwHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis:\n",
        "\n",
        "H₀ (Null Hypothesis): There is no significant difference in the distribution of Open, High, Low, and Close prices. Stock price movements are stable with minimal extreme variations.\n",
        "\n",
        "H₁ (Alternative Hypothesis): There are significant variations in stock prices, and extreme price movements (outliers) indicate market volatility.\n",
        "\n",
        "Interpretation:\n",
        "The median price for each category (Open, High, Low, Close) is positioned closer to the lower quartile (Q1), suggesting a right-skewed distribution. This means prices tend to have occasional sharp increases rather than sharp drops.\n",
        "The IQR (Interquartile Range) for all categories is relatively broad, indicating fluctuations in stock prices.\n",
        "\n",
        "The presence of outliers in all four price categories suggests that there were unusual price movements on certain days.\n",
        "High and Close prices have more outliers, indicating that stock prices experienced sudden spikes.\n",
        "\n",
        "This could be due to external market events, earnings reports, or investor sentiment shifts.\n",
        "\n",
        "Conclusion:\n",
        "Since outliers exist in all categories, stock prices are subject to high fluctuations on certain days.\n",
        "The data shows that sudden price spikes (outliers in High & Close prices) are more common than sudden drops, which aligns with the trend of stocks reacting strongly to positive news."
      ],
      "metadata": {
        "id": "D-RvE88uTt-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning & Preprocessing**"
      ],
      "metadata": {
        "id": "5fFiTP_VVGSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log Transformation to handle skewness"
      ],
      "metadata": {
        "id": "uIfue_zsVMfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col= ['Open', 'High', 'Low', 'Close']\n",
        "for i in col:\n",
        "    df[i] = np.log(df[i])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "XrvE2EL3VFny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subplots\n",
        "fig, axes = plt.subplots(2,2, figsize=(12,8))\n",
        "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
        "\n",
        "for i, col in enumerate(col):  # Use transformed columns\n",
        "    sns.histplot(df[col], kde=True, color='green', stat='density', bins=30, ax=axes[i],edgecolor='black')\n",
        "    axes[i].set_title(f'Distribution of {col} (Log Transformed)')\n",
        "    axes[i].set_xlabel(col)\n",
        "    axes[i].set_ylabel('Density')\n",
        "\n",
        "    # Calculate skewness\n",
        "    skewness = df[col].skew()\n",
        "\n",
        "    # Plot mean and median lines and save the line objects\n",
        "    mean_line = axes[i].axvline(df[col].mean(), color='red', linestyle='dashed', linewidth=1)\n",
        "    median_line = axes[i].axvline(df[col].median(), color='green', linestyle='dashed', linewidth=1)\n",
        "\n",
        "    # Create legend with the line objects\n",
        "    axes[i].legend([mean_line, median_line], ['Mean', 'Median'])\n",
        "\n",
        "    # Annotate skewness\n",
        "    axes[i].text(0.95, 0.95, f'Skewness: {skewness:.2f}',\n",
        "                 transform=axes[i].transAxes,\n",
        "                 horizontalalignment='right',\n",
        "                 verticalalignment='top',\n",
        "                 fontsize=12)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fpcWmdBpWXML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log Transformation Impact\n",
        "\n",
        "The histograms depict the distributions of Open, High, Low, and Close prices after applying a log transformation.\n",
        "Log transformation is useful for stabilizing variance and making the data more normally distributed.\n",
        "\n",
        "Skewness Analysis:\n",
        "Skewness values are close to 0 for all four variables, indicating that the distributions are nearly symmetrical.\n",
        "Log transformation successfully reduced any original skewness, making the data more normally distributed.\n",
        "\n",
        "Density and Shape\n",
        "The distributions appear fairly uniform with no significant outliers or extreme asymmetry.\n",
        "\n",
        "Kernel Density Estimation (KDE) overlay shows a peak around the middle values, reinforcing the symmet"
      ],
      "metadata": {
        "id": "r_bOGu4mXL7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Scaling **"
      ],
      "metadata": {
        "id": "4ciioixgXu4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define columns to standardize\n",
        "cols_to_standardize = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply standardization (Z-score normalization)\n",
        "df[cols_to_standardize] = scaler.fit_transform(df[cols_to_standardize])\n",
        "\n",
        "# Display the first few rows to verify transformation\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "kwdELNkMXeX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop(columns=['Close'])  # Features (independent variables)\n",
        "y = df['Close']  # Target variable"
      ],
      "metadata": {
        "id": "FYUM42_EYYPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.head()"
      ],
      "metadata": {
        "id": "9UyVdcnUYc9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split as tts"
      ],
      "metadata": {
        "id": "Ge8pSi9MYyYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = tts(x, y, test_size=0.2, random_state=42)\n",
        "# Print shapes to verify correctness\n",
        "print(f\"xtrain shape: {x_train.shape}, ytrain shape: {y_train.shape}\")\n",
        "print(f\"xtest shape: {x_test.shape}, ytest shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "NpGhC9_XYzz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL DEVELOPMENT**"
      ],
      "metadata": {
        "id": "enTsfdwuZKAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n"
      ],
      "metadata": {
        "id": "PoCq9-e-ZNe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. LINEAR REGRESSION"
      ],
      "metadata": {
        "id": "eOF9ieGWZZS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(x_train, y_train)\n",
        "y_pred_lr = lr.predict(x_test)\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
        "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "\n",
        "# Predictions on train and test sets\n",
        "y_train_pred = lr.predict(x_train)\n",
        "y_test_pred = lr.predict(x_test)\n",
        "\n",
        "# Calculate R2 and RMSE for training set\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "\n",
        "# Calculate R2 and RMSE for test set\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "# Print results\n",
        "print(f\"Linear Regression - Train R2 Score: {r2_train:.4f}, Train RMSE: {rmse_train:.4f}\")\n",
        "print(f\"Linear Regression - Test R2 Score: {r2_test:.4f}, Test RMSE: {rmse_test:.4f}\")\n",
        "\n",
        "print(f'Linear Regression - R2 Score: {r2_lr:.4f}')\n",
        "print(f'Linear Regression - RMSE: {rmse_lr:.4f}')"
      ],
      "metadata": {
        "id": "bXxECdGJZWhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Model is good.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}